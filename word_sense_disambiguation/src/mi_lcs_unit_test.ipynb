{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Case for Resnik Sim\n",
    "\n",
    "To test your program for computing Resnik Similarity, a good way to write a unit test is to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\priyak\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet_ic to\n",
      "[nltk_data]     C:\\Users\\priyak\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet_ic is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load our information content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet, wordnet_ic\n",
    "from nltk.corpus.reader.wordnet import information_content\n",
    "ic_data = wordnet_ic.ic('ic-brown-resnik-add1.dat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convenience Functions\n",
    "\n",
    "Let's write one function to lookup a synset by the \"necktie.n.01\" string format, since this doesn't appear to be implemented in NLTK.\n",
    "\n",
    "Let's also write a function to look up the information content we loaded earlier for a given synset using the same format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset <necktie.n.01> with information content: ~10.517\n"
     ]
    }
   ],
   "source": [
    "def synset_by_repr(r):\n",
    "    \"\"\"\n",
    "    Given a synset in the 'necktie.n.01' format, return the synset.\n",
    "    \n",
    "    :rtype: Synset\n",
    "    \"\"\"\n",
    "    lemma, pos, index = r.split('.')\n",
    "    synsets = wordnet.synsets(lemma, pos)\n",
    "    if synsets and len(synsets) > (int(index)-1):\n",
    "        return synsets[int(index)-1]\n",
    "\n",
    "def ic(r):\n",
    "    if r:\n",
    "        return information_content(r, ic_data)\n",
    "\n",
    "def print_ic(r):\n",
    "    \"\"\"\n",
    "    :type r: Synset\n",
    "    \"\"\"\n",
    "    print('Synset <{}> with information content: ~{:.3f}'.format(r.name(), ic(r)))\n",
    "    \n",
    "    \n",
    "\n",
    "necktie_syn = synset_by_repr('necktie.n.01')\n",
    "print_ic(synset_by_repr('necktie.n.01'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determining LCS\n",
    "\n",
    "Determining the LCS is easy enough, but first let's put together a quick way to visualize the ancestors of a given synset.\n",
    "\n",
    "NLTK makes this somewhat easier by the existence of the `hypernym_paths()` function, which gives us all the possible paths to the root element of a given synset (note that there may be multiple parents of certain nodes, thus multiple paths).\n",
    "\n",
    "Let's create this function then use it to verify that we are getting the correct LCS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hypernyms for car.n.01:\n",
      "- - - - - - - - - - - - - - - - - - - - \n",
      "line.n.22\n",
      " ↑ merchandise.n.01\n",
      " ↑ commodity.n.01\n",
      " ↑ artifact.n.01\n",
      " ↑ whole.n.02\n",
      " ↑ object.n.01\n",
      " ↑ physical_entity.n.01\n",
      " ↑ entity.n.01 *\n",
      "Hypernyms for journey.n.01:\n",
      "- - - - - - - - - - - - - - - - - - - - \n",
      "line.n.23\n",
      " ↑ carrier.n.05\n",
      " ↑ business.n.01\n",
      " ↑ enterprise.n.02\n",
      " ↑ organization.n.01\n",
      " ↑ social_group.n.01\n",
      " ↑ group.n.01\n",
      " ↑ abstraction.n.06\n",
      " ↑ entity.n.01 *\n",
      "Hypernyms for car.n.01:\n",
      "- - - - - - - - - - - - - - - - - - - - \n",
      "cast.n.01\n",
      " ↑ gathering.n.01\n",
      " ↑ social_group.n.01\n",
      " ↑ group.n.01\n",
      " ↑ abstraction.n.06\n",
      " ↑ entity.n.01 *\n",
      "Hypernyms for journey.n.01:\n",
      "- - - - - - - - - - - - - - - - - - - - \n",
      "newsworthiness.n.01\n",
      " ↑ interest.n.03\n",
      " ↑ power.n.01\n",
      " ↑ quality.n.01\n",
      " ↑ attribute.n.02\n",
      " ↑ abstraction.n.06\n",
      " ↑ entity.n.01 *\n"
     ]
    }
   ],
   "source": [
    "def print_hypernym_paths(synset):\n",
    "    \"\"\"\n",
    "    :type synset: Synset\n",
    "    \"\"\"\n",
    "    for path in synset.hypernym_paths():\n",
    "        print('\\n \\u2191 '.join([path_elt.name() for path_elt in reversed(path)]) + ' *')\n",
    "\n",
    "doctor_1 = synset_by_repr('line.n.22')\n",
    "nurse_1 = synset_by_repr('line.n.23')\n",
    "\n",
    "print('Hypernyms for car.n.01:\\n'+'- '*20)\n",
    "print_hypernym_paths(doctor_1)\n",
    "\n",
    "print('Hypernyms for journey.n.01:\\n'+'- '*20)\n",
    "print_hypernym_paths(nurse_1)\n",
    "\n",
    "doctor_1 = synset_by_repr('cast.n.01')\n",
    "nurse_1 = synset_by_repr('news.n.05')\n",
    "\n",
    "print('Hypernyms for car.n.01:\\n'+'- '*20)\n",
    "print_hypernym_paths(doctor_1)\n",
    "\n",
    "print('Hypernyms for journey.n.01:\\n'+'- '*20)\n",
    "print_hypernym_paths(nurse_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding this into a Test Case\n",
    "\n",
    "So, looking at our lists above, we should be able to quickly find that the LCS for these synsets is `health_professional.n.01`. \n",
    "\n",
    "We can encode this into a unit test for finding the LCS in something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unittest import TestCase, main\n",
    "\n",
    "def lowest_common_subsumer(syn_1, syn_2):\n",
    "    \"\"\"\n",
    "    :type syn_1: Synset\n",
    "    :type syn_2: Synset\n",
    "    \n",
    "    Code to retrieve the lowest common subsumer. Replace this\n",
    "    with your real code, don't use the NLTK implementation!\n",
    "    \"\"\"\n",
    "    return set(syn_1.lowest_common_hypernyms(syn_2))\n",
    "\n",
    "class LCSTests(TestCase):\n",
    "    def test_nurse_doctor(self):\n",
    "        self.assertSetEqual({synset_by_repr('health_professional.n.01')},\n",
    "                           lowest_common_subsumer(nurse_1, doctor_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding More Test Cases\n",
    "\n",
    "Using the model of the test case written above, can you now find the LCS between 'dog.n.01' and 'fish.n.01'?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "dog_syn = synset_by_repr('dog.n.01')\n",
    "fish_syn = synset_by_repr('fish.n.01')\n",
    "\n",
    "##### ADD CODE TO EXPLORE HYPERNYMS/SYNSETS HERE ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding the MI LCS\n",
    "\n",
    "Now, since we're ultimately interested in finding the appropriate sense for a word given multiple senses for the target word and its' probe words, let's try testing out a sub-problem for solving the meaning for ***bowl***, whether a type of container or the sporting event.\n",
    "\n",
    "The WordNet listing for bowl [can be found here](http://wordnetweb.princeton.edu/perl/webwn?s=bowl&sub=Search+WordNet&o2=&o0=1&o8=1&o1=1&o7=&o5=&o9=&o6=&o3=&o4=&h=1112231231223123123123022220).\n",
    "\n",
    "Let's start with the first sense, `bowl.n.01`, the type of kitchen utensil. And we'll use a probe word `plate`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "bowl_sense_1 = synset_by_repr('bowl.n.01')\n",
    "plate_synsets = wordnet.synsets('plate', pos='n')\n",
    "\n",
    "# \"Plate\" has 15 synsets! Let's see what the LCS for each, with bowl.n.01:\n",
    "most_informative = (None, 0)\n",
    "for plate_synset in plate_synsets:\n",
    "    # Write\n",
    "\n",
    "# Now, what about the fifth sense of \"bowl,\" as in a stadium?\n",
    "bowl_sense_5 = synset_by_repr('bowl.n.05')\n",
    "house_synsets = wordnet.synsets('house', pos='n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the Test Cases\n",
    "\n",
    "The following will run all of the unit tests declared above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.003s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x11b99c358>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main(argv=['first-arg-is-ignored'], exit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "nteract": {
   "version": "0.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
